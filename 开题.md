## 概念引入：

端到端深度学习编译器：以 TVM 为例。

TVM：End to End learning-based deep learning compiler

一般结构：

    传统：由模型构造计算图，将计算图中的算子用高性能库中的实现替代（如cudnn, mkl-dnn等）。

<img src="https://img-blog.csdnimg.cn/20210218205452250.png" title="" alt="" data-align="left">

根据计算图的特点，可以在图级进行编译优化：

1. 算子融合 Conv+Relu，减少内存访问

2. 

![](D:\Users\liukangcheng\AppData\Roaming\marktext\images\2022-11-15-16-12-06-image.png)

中间问题：

1. 子图划分

2. 编译参数优化

已有方法：

子图划分方法：

Ansor --> Relay: A High-Level Compiler for Deep Learning

算子融合方法：[Op Fusion（一）： 什么是算子融合 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/581755093)

编译参数搜索：Cost Model + SA/ Template-guided RL

由计算子图生成代码：

1. Template-Guided Optimization

2. Sequential construction based search

3. Ansor 基于规则产生搜索空间 + Program sampler + Evolutionary Search

深度学习编译器调研： The Deep Learning Compiler: A Comprehensive Survey



要做的事：

1. 如何将计算图划分为子图
   
   1. RL方法，对比基于规则的子图划分；评价标准为执行时间

2. 对于子图，如何得到最优编译配置参数
   
   1. RL方法，对比手工参数；评价标准为执行时间
